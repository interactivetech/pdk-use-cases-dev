name: Train Test
workspace: Andrew
project: PDK Test
# bind_mounts:
#     - host_path: /run/determined/workdir/shared_fs/
#       container_path: /tmp/data/
#       read_only: true
data:
    pachyderm:
        host:
        port:
        repo:
        branch:
        token:
        previous_commit:
profiling:
 enabled: true
 begin_on_batch: 0
 end_after_batch: null
hyperparameters:
    lr: 0.02
    momentum: 0.9
    global_batch_size: 16
    weight_decay: 1.0e-4
    gamma: 0.1
    warmup: linear
    warmup_iters: 200
    warmup_ratio: 0.001
    pretrained_model: "/lus/aiholus1/disk/andrew.mendez/frcnn_xview.pth"
    finetune_ckpt: "/lus/aiholus1/disk/andrew.mendez/model_479.pth"
    step1: 504 # 14 epochs: 14*36 == 504
    step2: 540 # 15 epochs: 15*36 == 540
    model: fasterrcnn_resnet50_fpn
    # Dataset
    dataset_file: coco
    backend: local # specifiy the backend you want to use.  one of: gcs, aws, fake, local
    data_dir: "/lus/aiholus1/disk/andrew.mendez/xview_dataset/" # bucket name if using gcs or aws, otherwise directory to dataset
    masks: false
    num_workers: 4
    device: cuda
environment:
    image: mendeza/obj-det-pdk-train-env:0.0.2
    environment_variables:                                                                          
        - NCCL_DEBUG=INFO                                                                           
        # You may need to modify this to match your network configuration.                          
        - NCCL_SOCKET_IFNAME=ens,eth,ib

scheduling_unit: 400
min_validation_period:
    batches: 36 # For training

searcher:
  name: single
  metric: mAP
  smaller_is_better: true
  max_length:
    batches: 2 # 1*(579/16) = 1*36
records_per_epoch: 32 # 32 records / 16
resources:
    slots_per_trial: 1
    shm_size: 2000000000
max_restarts: 0

entrypoint: python3 -m determined.launch.torch_distributed --trial model_def:ObjectDetectionTrial